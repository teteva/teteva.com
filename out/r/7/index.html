<!DOCTYPE html>
<html lang="uk-UA">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>
    From Online | 7 
  </title>
  <meta name="description" content="The personal site & portfolio of Ukraine-based creative researcher Vadim Teteva" />
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-S0WB0Z195P"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-S0WB0Z195P');
  </script>
  <link rel="apple-touch-icon" sizes="180x180" href="/meta/apple-touch-icon.png" />
  <link rel="icon" type="image/png" sizes="32x32" href="/meta/favicon-32x32.png" />
  <link rel="icon" type="image/png" sizes="16x16" href="/meta/favicon-16x16.png" />
  <link rel="me" href="https://mastodon.social/@teteva" />
  <!-- <link rel="me" href="https://github.com/xdesro"> -->
  <link rel="manifest" href="/meta/site.webmanifest" />
  <link rel="mask-icon" href="/meta/safari-pinned-tab.svg" color="#000000" />
  <meta name="msapplication-TileColor" content="#f5f5f5" />
  <meta name="theme-color" content="#F5F5F5" />
  <meta name="generator" content="eleventy">

  <!-- Indieweb -->
  <link rel="authorization_endpoint" href="https://indieauth.com/auth">
  <link rel="token_endpoint" href="https://tokens.indieauth.com/token">

  <!-- Webmentions -->
  <link rel="webmention" href="https://webmention.io/teteva.com/webmention" />
  <link rel="pingback" href="https://webmention.io/teteva.com/xmlrpc" />

  <!-- Aperture -->
  <!-- to do -->
  <!-- <link rel="microsub" href="https://aperture.p3k.io/microsub/816"> -->

  <link rel="preload" href="/fonts/silk-serif/silk-serif.woff2" as="font" type="font/woff2" crossorigin />
  <link rel="preload" href="/fonts/iA-Fonts-master/iAWriterQuattro/Webfonts/iAWriterQuattroS-Regular.woff2" as="font" type="font/woff2" crossorigin />
  <link rel="preload" href="/fonts/iA-Fonts-master/iAWriterQuattro/Webfonts/iAWriterQuattroS-Bold.woff2" as="font" type="font/woff2" crossorigin />
  <link rel="stylesheet" href="/css/index.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css">

  <script>
    if (localStorage.getItem('darkMode') == 'true')
      document.documentElement.setAttribute('dark', true);
  </script>

  <meta name="twitter:site" content="@tetyva" />
  <meta name="twitter:title" content="Teteva From Online | 7 " />
  <meta property="og:title" content="Teteva From Online | 7 ">
  <meta property="og:type" content="website">

  
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:description"
      content="The personal site & portfolio of Ukraine-based creative researcher Vadim Teteva" />
    <meta name="twitter:image" content="https://teteva.com/meta/og-default.jpg" />

    <meta property="og:url" content="https://teteva.com">
    <meta property="og:title" content="From Online">
    <meta property="og:description" content="The personal site & portfolio of Ukraine-based creative researcher Vadim Teteva">
    <meta property="og:image" content="https://teteva.com/meta/og-default.jpg">
  
  
    <meta name="robots" content="noindex">
  
</head>

<body>
  <div data-server-rendered="true"><main id="main" data-router-wrapper><article data-router-view="post" class="post"><div class="post__intro"><ul class="post__tags"><li>forreader</li></ul> <nav class="table-of-contents"><a class="table-of-contents__lowercase">28 вер. 2024 р., 15:00</a></nav></div> <div class="new__intro"><p>Выход за рамки графических процессоров: Эволюционирующий ландшафт чипов и ускорителей искусственного интеллекта<br>
Эта статья является частью специального выпуска VB под названием “Соответствие назначению: адаптация инфраструктуры искусственного интеллекта”. Смотрите другие статьи здесь.<br>
Центры обработки данных - это серверная часть известного нам Интернета. Будь то Netflix или Google, все крупные компании используют центры обработки данных и компьютерные системы, которые они размещают, для предоставления цифровых услуг конечным пользователям. По мере того как предприятия переключают свое внимание на передовые рабочие нагрузки с использованием искусственного интеллекта, традиционные серверы центров обработки данных, ориентированные на процессоры, совершенствуются за счет интеграции новых специализированных чипов или “сопроцессоров”.<br>
По сути, идея, стоящая за этими сопроцессорами, заключается в том, чтобы внедрить своего рода дополнение для увеличения вычислительной мощности серверов. Это позволяет им выполнять вычислительные задачи, связанные с рабочими нагрузками, такими как обучение ИИ, логический вывод, ускорение баз данных и сетевые функции. За последние несколько лет графические процессоры, разработанные компанией Nvidia, стали популярным выбором в качестве сопроцессоров благодаря их способности обрабатывать большие объемы данных с непревзойденной скоростью. Согласно исследованию Futurum Group, в прошлом году из-за возросшего спроса на графические процессоры приходилось 74% сопроцессоров, обеспечивающих использование искусственного интеллекта в центрах обработки данных.<br>
Согласно исследованию, ожидается, что доминирование графических процессоров будет только расти, а доходы от этой категории будут расти на 30% ежегодно и составят 102 миллиарда долларов к 2028 году. Но вот в чем дело: хотя графические процессоры с их архитектурой параллельной обработки данных являются надежным помощником в ускорении всех видов крупномасштабных рабочих нагрузок ИИ (таких как обучение и запуск огромных языковых моделей с триллионами параметров или секвенирование генома), общая стоимость владения ими может быть очень высокой. Например, ожидается, что флагманский “суперчип” Nvidia GB200, который сочетает в себе процессор Grace и два графических процессора B200, будет стоить от 60 000 до 70 000 долларов. Сервер с 36 такими суперчипами оценивается примерно в 2 миллиона долларов.<br>
Хотя в некоторых случаях, например, в крупномасштабных проектах, это может сработать, это подходит не для каждой компании. Многие ИТ-менеджеры предприятий стремятся внедрить новые технологии для поддержки отдельных рабочих нагрузок ИИ с низкой и среднеинтенсивной нагрузкой, уделяя особое внимание общей стоимости владения, масштабируемости и интеграции. В конце концов, большинство моделей искусственного интеллекта (сети глубокого обучения, нейронные сети, модели больших языков и т.д.) находятся на стадии разработки, и потребности смещаются в сторону логического вывода с помощью искусственного интеллекта и повышения производительности для конкретных рабочих нагрузок, таких как распознавание изображений, рекомендательные системы или идентификация объектов, при этом оставаясь эффективными.</p>
<blockquote>
<blockquote>
<p>Не пропустите наш специальный выпуск: “Соответствие назначению: адаптация инфраструктуры искусственного интеллекта”.&lt;&lt;<br>
Именно здесь появляется растущий рынок специализированных процессоров и ускорителей искусственного интеллекта, создаваемых производителями микросхем, стартапами и облачными провайдерами.<br>
Что такое процессоры и ускорители искусственного интеллекта?<br>
По сути, процессоры и ускорители искусственного интеллекта - это чипы, которые встроены в процессорную экосистему серверов и ориентированы на конкретные функции искусственного интеллекта. Обычно они основаны на трех ключевых архитектурах: специализированные интегральные схемы (ASIC), программируемые в полевых условиях вентильные матрицы (FPGA) и самая последняя инновация - нейронные процессоры (NPU).<br>
ASIC и FPGA существуют уже довольно давно, и единственным отличием между ними является возможность программирования. Микросхемы ASIC создаются на заказ с нуля для решения конкретной задачи (которая может быть связана с искусственным интеллектом, а может и не быть связана с ним), в то время как ПЛИС могут быть перенастроены на более позднем этапе для реализации пользовательской логики. NPU, со своей стороны, отличаются от обоих тем, что служат специализированным оборудованием, которое может только ускорить рабочие нагрузки AI /ML, такие как вывод и обучение нейронных сетей.<br>
“Ускорители, как правило, способны выполнять любую функцию по отдельности, и иногда при использовании микросхем ASIC с несколькими чипами они могут быть способны работать с несколькими различными приложениями. NPU - это хороший пример специализированного чипа (обычно являющегося частью системы), который может выполнять ряд задач матричной математики и нейронных сетей, а также различные задачи логического вывода с меньшими затратами энергии”, - говорит генеральный директор Futurum group Дэниел Ньюман в интервью Venturebeat.<br>
Самое приятное то, что ускорители, особенно ASIC и NPU, созданные для конкретных приложений, могут оказаться более эффективными, чем графические процессоры, с точки зрения стоимости и энергопотребления.<br>
“Проекты графических процессоров в основном основаны на арифметико-логических блоках (ALU), так что они могут выполнять тысячи вычислений одновременно, в то время как проекты ускорителей искусственного интеллекта в основном основаны на ядрах тензорных процессоров (TPC) или модулях. В целом, производительность ускорителей искусственного интеллекта в сравнении с производительностью графических процессоров основана на фиксированной функции этой конструкции”, - рассказывает VentureBeat Рохит Бадлани, генеральный менеджер IBM по облачным и отраслевым платформам.<br>
В настоящее время IBM придерживается гибридного облачного подхода и использует в своем стеке несколько графических процессоров и ускорителей искусственного интеллекта, включая решения от Nvidia и Intel, чтобы предоставить предприятиям возможность выбора для удовлетворения потребностей их уникальных рабочих нагрузок и приложений с высокой производительностью и эффективностью.<br>
“Наши комплексные решения призваны помочь изменить подходы предприятий, разработчиков и сообщества разработчиков с открытым исходным кодом к созданию и использованию генеративного ИИ. Акселераторы искусственного интеллекта - это одно из предложений, которое, по нашему мнению, очень полезно для клиентов, желающих внедрить генеративный ИИ”, - сказал Бадлейни. Он добавил, что, хотя графические процессоры лучше всего подходят для обучения и тонкой настройки больших моделей, существует множество задач искусственного интеллекта, с которыми ускорители могут справиться одинаково хорошо - и с меньшими затратами.<br>
Например, облачные виртуальные серверы IBM используют ускоритель Intel Gaudi 3 с пользовательским программным пакетом, разработанным специально для обработки логических выводов и больших требований к памяти. Компания также планирует использовать ускоритель для тонкой настройки и небольших учебных нагрузок с помощью небольших кластеров из нескольких систем.<br>
“Ускорители искусственного интеллекта и графические процессоры могут эффективно использоваться для некоторых аналогичных рабочих нагрузок, таких как LLMS и модели диффузии (генерация изображений, подобных Stable Diffusion), а также для стандартного распознавания объектов, классификации и озвучивания. Однако преимущества и различия между ускорителями искусственного интеллекта и графическими процессорами полностью зависят от дизайна поставщика оборудования. Например, ускоритель искусственного интеллекта Gaudi 3 был разработан таким образом, чтобы обеспечить значительное увеличение объема вычислений, пропускной способности памяти и энергоэффективности на основе архитектуры”, - пояснил Бадлейни.<br>
Это, по его словам, напрямую отражается на соотношении цены и качества.<br>
Помимо Intel, другие ускорители искусственного интеллекта также привлекают внимание на рынке. Это включает в себя не только пользовательские чипы, созданные для поставщиков общедоступных облачных сервисов, таких как Google, AWS и Microsoft, но и специализированные продукты (в некоторых случаях NPU) от таких стартапов, как Groq, Graphcore, SambaNova Systems и Cerebras Systems. Все они выделяются по-своему, бросая вызов графическим процессорам в разных областях.<br>
В одном случае Tractable, компания, разрабатывающая искусственный интеллект для анализа ущерба имуществу и транспортным средствам при страховых выплатах, смогла использовать интеллектуальную систему Graphcore Processing Unit-POD (специализированное предложение NPU) для значительного повышения производительности по сравнению с графическими процессорами, которые они использовали ранее.<br>
“Мы увидели увеличение скорости примерно в 5 раз”, - написал в своем блоге Разван Ранка, соучредитель и технический директор Tractable. - Это означает, что теперь исследователь может потенциально провести в пять раз больше экспериментов, а значит, мы ускоряем весь процесс исследований и разработок и в конечном итоге получаем более совершенные модели в наших продуктах”.<br>
В некоторых случаях процессоры искусственного интеллекта также увеличивают нагрузку на обучение. Например, суперкомпьютер искусственного интеллекта в центре обработки данных Aleph Alpha использует Cerebras CS-3, систему, работающую на базе Wafer Scale Engine третьего поколения с 900 000 ИИ-ядрами, для создания суверенных ИИ-моделей следующего поколения. Даже недавно представленный Google пользовательский модуль ASIC, TPU v5p, позволяет выполнять некоторые задачи по обучению ИИ для таких компаний, как Salesforce и Lightricks.<br>
Каким должен быть подход к выбору ускорителей?<br>
Теперь, когда стало известно, что помимо графических процессоров существует множество ИИ-процессоров, ускоряющих рабочие нагрузки ИИ, особенно логический вывод, возникает вопрос: как ИТ-менеджеру выбрать наилучший вариант для инвестиций? Некоторые из этих чипов могут обеспечивать хорошую производительность и эффективность использования, но могут быть ограничены в плане задач искусственного интеллекта, с которыми они могут справиться из-за своей архитектуры. Другие могут выполнять больше функций, но разница в общей стоимости владения может быть не такой существенной по сравнению с графическими процессорами.<br>
Поскольку ответ зависит от конструкции чипов, все эксперты, с которыми беседовал VentureBeat, предположили, что выбор должен основываться на масштабе и типе обрабатываемой рабочей нагрузки, данных, вероятности продолжения итераций/изменений, а также затратах и потребностях в доступности.<br>
По словам Дэниела Кирни, технического директора Sustainable Metal Cloud, которая помогает компаниям в обучении ИИ и выводах, предприятиям также важно проводить тесты, чтобы оценить соотношение цены и качества и убедиться, что их команды знакомы с более широкой программной экосистемой, поддерживающей соответствующие ускорители искусственного интеллекта.<br>
“Несмотря на то, что подробную информацию о рабочей нагрузке может быть сложно получить заранее или она может быть неубедительной для принятия решений, рекомендуется проводить сравнительный анализ и тестирование с использованием репрезентативных рабочих нагрузок, тестирования в реальных условиях и доступной экспертной информации из реального мира, где это возможно, чтобы обеспечить основанный на данных подход к выбору правильного ИИ ускоритель для правильной рабочей нагрузки. Это предварительное расследование может значительно сэкономить время и деньги, особенно при выполнении крупных и дорогостоящих работ по обучению”, - предположил он.<br>
По оценкам, общий объем рынка оборудования для искусственного интеллекта, включая чипы, ускорители и графические процессоры, будет ежегодно увеличиваться на 30% и к 2028 году достигнет 138 миллиардов долларов.</p>
</blockquote>
</blockquote>
</div></article></main></div>
  <button class="theme-toggle" aria-label="theme-toggle">
    <svg fill="currentColor" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 267 267">
      <path fill-rule="evenodd" clip-rule="evenodd"
        d="M133.5 244c61.027 0 110.5-49.473 110.5-110.5C244 72.472 194.527 23 133.5 23 72.472 23 23 72.472 23 133.5 23 194.527 72.472 244 133.5 244zm0 23c73.73 0 133.5-59.77 133.5-133.5C267 59.77 207.23 0 133.5 0 59.77 0 0 59.77 0 133.5 0 207.23 59.77 267 133.5 267z" />
      <path
        d="M247 133c0-29.969-11.958-58.711-33.243-79.903C192.471 31.905 163.602 20 133.5 20c-30.102 0-58.971 11.905-80.257 33.097C31.958 74.288 20 103.03 20 133h227z" />
    </svg>
  </button>
  <div class="grid-overlay">
    <div class="grid-overlay__cell"></div>
    <div class="grid-overlay__cell"></div>
    <div class="grid-overlay__cell"></div>
    <div class="grid-overlay__cell"></div>
    <div class="grid-overlay__cell"></div>
    <div class="grid-overlay__cell"></div>
    <div class="grid-overlay__cell"></div>
    <div class="grid-overlay__cell"></div>
    <div class="grid-overlay__cell"></div>
    <div class="grid-overlay__cell"></div>
    <div class="grid-overlay__cell"></div>
    <div class="grid-overlay__cell"></div>
    <div class="grid-overlay__cell"></div>
    <div class="grid-overlay__cell"></div>
    <div class="grid-overlay__cell"></div>
    <div class="grid-overlay__cell"></div>
  </div>
  <script src="https://unpkg.com/splitting/dist/splitting.min.js"></script>
  <script src="/js/index.js" type="module"></script>
  <script async src="/js/transitions.js" type="module"></script>
  <!-- <script defer src="/js/gl.js" type="module"></script> -->
  <!-- <script async src="/js/gl.js" type="module"></script> -->
  <!-- <script src="/js/case-studies-gl.js" type="module"></script> -->
</body>

</html>
